{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0eb446b",
   "metadata": {},
   "source": [
    "# Predicting Higher Education Students Performance\n",
    "\n",
    "This project will use ML to predict whether students will have a good final grade based on personal characteristics, family characteristics, and education habits. If it is possible to predict which students would likely have a poor outcome, those students could be offered extra services to help them succeed.\n",
    "<br>The dataset has the final grades of students encoded by letter, this will be divided into 2 groups: those with a \"C\" or higher are considered \"good\" and those with less than a \"C\" are considered to be \"bad.\"\n",
    "<br>The dataset used is \"Higher Education Students Performance Evaluation\" made available by the Faculty of Engineering and Faculty of Educational Sciences students in 2019 and was downloaded from the UC Irvine Machine Learing Repository (https://archive.ics.uci.edu/dataset/856/higher+education+students+performance+evaluation).  \n",
    "\n",
    "This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
    "\n",
    "Citation: Yilmaz,Nevriye and Şekeroğlu,Boran. (2023). Higher Education Students Performance Evaluation. UCI Machine Learning Repository. https://doi.org/10.24432/C51G82."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625dd9b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "From the dataset documentation:\n",
    "\n",
    "Student ID<br/>\n",
    "1- Student Age (1: 18-21, 2: 22-25, 3: above 26)<br/>\n",
    "2- Sex (1: female, 2: male)<br/>\n",
    "3- Graduated high-school type: (1: private, 2: state, 3: other)<br/>\n",
    "4- Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)<br/>\n",
    "5- Additional work: (1: Yes, 2: No)<br/>\n",
    "6- Regular artistic or sports activity: (1: Yes, 2: No)<br/>\n",
    "7- Do you have a partner: (1: Yes, 2: No)<br/>\n",
    "8- Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)<br/>\n",
    "9- Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)<br/>\n",
    "10- Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)<br/>\n",
    "11- Mothersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)<br/>\n",
    "12- Fathersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)<br/>\n",
    "13- Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)<br/>\n",
    "14- Parental status: (1: married, 2: divorced, 3: died - one of them or both)<br/>\n",
    "15- Mothersâ€™ occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)<br/>\n",
    "16- Fathersâ€™ occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)<br/>\n",
    "17- Weekly study hours: (1: None, 2: <5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)<br/>\n",
    "18- Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)<br/>\n",
    "19- Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)<br/>\n",
    "20- Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)<br/>\n",
    "21- Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)<br/>\n",
    "22- Attendance to classes (1: always, 2: sometimes, 3: never)<br/>\n",
    "23- Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)<br/>\n",
    "24- Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)<br/>\n",
    "25- Taking notes in classes: (1: never, 2: sometimes, 3: always)<br/>\n",
    "26- Listening in classes: (1: never, 2: sometimes, 3: always)<br/>\n",
    "27- Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)<br/>\n",
    "28- Flip-classroom: (1: not useful, 2: useful, 3: not applicable)<br/>\n",
    "29- Cumulative grade point average in the last semester (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)<br/>\n",
    "30- Expected Cumulative grade point average in the graduation (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)<br/>\n",
    "31- Course ID<br/>\n",
    "32- OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)<br/>\n",
    "\n",
    "<hr> The dataset already has its categorical features coded to integers, and no feature has more than 10 values, so One-Hot-Encoding is not needed for this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90ed46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies.\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d26314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an engine to retrieve the data from PostgreSQL database.\n",
    "engine = create_engine(f\"postgresql://postgres:{db_password}@localhost:5432/student_data_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db577f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data and place it into a DataFrame\n",
    "sql_query = \"SELECT * FROM student_data\"\n",
    "student_df = pd.read_sql(sql_query, engine)\n",
    "student_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039d909",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29942f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Student ID column\n",
    "student_df = student_df.drop('STUDENT ID', axis=1)\n",
    "student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe23432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145 entries, 0 to 144\n",
      "Data columns (total 32 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   1          145 non-null    int64\n",
      " 1   2          145 non-null    int64\n",
      " 2   3          145 non-null    int64\n",
      " 3   4          145 non-null    int64\n",
      " 4   5          145 non-null    int64\n",
      " 5   6          145 non-null    int64\n",
      " 6   7          145 non-null    int64\n",
      " 7   8          145 non-null    int64\n",
      " 8   9          145 non-null    int64\n",
      " 9   10         145 non-null    int64\n",
      " 10  11         145 non-null    int64\n",
      " 11  12         145 non-null    int64\n",
      " 12  13         145 non-null    int64\n",
      " 13  14         145 non-null    int64\n",
      " 14  15         145 non-null    int64\n",
      " 15  16         145 non-null    int64\n",
      " 16  17         145 non-null    int64\n",
      " 17  18         145 non-null    int64\n",
      " 18  19         145 non-null    int64\n",
      " 19  20         145 non-null    int64\n",
      " 20  21         145 non-null    int64\n",
      " 21  22         145 non-null    int64\n",
      " 22  23         145 non-null    int64\n",
      " 23  24         145 non-null    int64\n",
      " 24  25         145 non-null    int64\n",
      " 25  26         145 non-null    int64\n",
      " 26  27         145 non-null    int64\n",
      " 27  28         145 non-null    int64\n",
      " 28  29         145 non-null    int64\n",
      " 29  30         145 non-null    int64\n",
      " 30  COURSE ID  145 non-null    int64\n",
      " 31  GRADE      145 non-null    int64\n",
      "dtypes: int64(32)\n",
      "memory usage: 36.4 KB\n"
     ]
    }
   ],
   "source": [
    "# check number of unique values for each feature\n",
    "student_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c5bfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>COURSE ID</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5  6  7  8  9  10  ...  23  24  25  26  27  28  29  30  \\\n",
       "0    2  0  3  3  1  0  0  1  1   1  ...   1   1   3   2   1   2   1   1   \n",
       "1    2  0  3  3  1  0  0  1  1   1  ...   1   1   3   2   3   2   2   3   \n",
       "2    2  0  2  3  0  0  0  2  4   2  ...   1   1   2   2   1   1   2   2   \n",
       "3    1  1  1  3  1  0  1  2  1   2  ...   1   2   3   2   2   1   3   2   \n",
       "4    2  0  1  3  0  0  1  3  1   4  ...   2   1   2   2   2   1   2   2   \n",
       "..  .. .. .. .. .. .. .. .. ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "140  2  1  2  3  1  1  0  1  1   2  ...   1   1   2   1   2   1   3   3   \n",
       "141  1  1  2  4  0  0  0  1  4   2  ...   1   1   3   2   2   1   5   3   \n",
       "142  1  1  1  4  0  0  0  1  1   1  ...   1   1   3   3   2   1   4   3   \n",
       "143  2  1  2  4  1  1  1  5  2   3  ...   2   1   2   1   2   1   5   3   \n",
       "144  1  1  1  5  0  0  0  3  1   1  ...   2   1   3   2   3   1   5   4   \n",
       "\n",
       "     COURSE ID  GRADE  \n",
       "0            1      1  \n",
       "1            1      1  \n",
       "2            1      1  \n",
       "3            1      1  \n",
       "4            1      1  \n",
       "..         ...    ...  \n",
       "140          9      5  \n",
       "141          9      5  \n",
       "142          9      1  \n",
       "143          9      4  \n",
       "144          9      3  \n",
       "\n",
       "[145 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the \"2\" with \"0\" used for \"no\" and \"male\" in features 2, 5, 6, 7, 20\n",
    "mapping_dict = {2:0, 1:1}  # Defines the mapping dictionary\n",
    "mapped_student_df = student_df\n",
    "mapped_student_df.loc[:,['2', '5', '6', '7', '20']] = mapped_student_df[['2', '5', '6', '7', '20']].applymap(mapping_dict.get)\n",
    "mapped_student_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57396d76",
   "metadata": {},
   "source": [
    "\"Machine learning: one-hot encoding vs integer encoding\" by Stéphanie Crêteur,Published in Geek Culture, Dec 16, 2022, https://medium.com/geekculture/machine-learning-one-hot-encoding-vs-integer-encoding-f180eb831cf1 was consulted when deciding which categories made sense to leave integer encoded, and which to ues One-Hot Encoding on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8a11d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>28_3</th>\n",
       "      <th>COURSE ID_1</th>\n",
       "      <th>COURSE ID_2</th>\n",
       "      <th>COURSE ID_3</th>\n",
       "      <th>COURSE ID_4</th>\n",
       "      <th>COURSE ID_5</th>\n",
       "      <th>COURSE ID_6</th>\n",
       "      <th>COURSE ID_7</th>\n",
       "      <th>COURSE ID_8</th>\n",
       "      <th>COURSE ID_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  4  5  6  7  8  11  12  13  ...  28_3  COURSE ID_1  COURSE ID_2  \\\n",
       "0  2  0  3  1  0  0  1   1   2   3  ...     0            1            0   \n",
       "1  2  0  3  1  0  0  1   2   3   2  ...     0            1            0   \n",
       "2  2  0  3  0  0  0  2   2   2   2  ...     0            1            0   \n",
       "3  1  1  3  1  0  1  2   1   2   5  ...     0            1            0   \n",
       "4  2  0  3  0  0  1  3   3   3   2  ...     0            1            0   \n",
       "5  2  0  3  0  0  0  2   3   3   2  ...     0            1            0   \n",
       "6  1  0  4  0  0  0  1   1   3   1  ...     1            1            0   \n",
       "7  1  1  3  1  1  1  2   4   3   1  ...     0            1            0   \n",
       "8  2  1  3  0  1  1  1   2   4   2  ...     0            1            0   \n",
       "9  2  1  3  0  0  1  3   1   2   3  ...     0            1            0   \n",
       "\n",
       "   COURSE ID_3  COURSE ID_4  COURSE ID_5  COURSE ID_6  COURSE ID_7  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "5            0            0            0            0            0   \n",
       "6            0            0            0            0            0   \n",
       "7            0            0            0            0            0   \n",
       "8            0            0            0            0            0   \n",
       "9            0            0            0            0            0   \n",
       "\n",
       "   COURSE ID_8  COURSE ID_9  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "5            0            0  \n",
       "6            0            0  \n",
       "7            0            0  \n",
       "8            0            0  \n",
       "9            0            0  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get_dummies for categorical data where numeric values don't make sense\n",
    "# These are columns 3, 9, 10, 14, 15, 16, 23, 24, 28, COURSE ID\n",
    "encoded_student_df = pd.get_dummies(mapped_student_df, \n",
    "                                     columns=['3', '9', '10', '14', '15', '16', '23', '24', '28', 'COURSE ID'])\n",
    "encoded_student_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700f1e2",
   "metadata": {},
   "source": [
    "The documentation indicates that the values of the rest of the columns are very close, so no need to apply StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba56bf4",
   "metadata": {},
   "source": [
    "## Binomial Logistic Regression\n",
    "(This is the type covered in the bootcamp simply called \"Logistic Regression.\" There are 2 values for the target variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978ddf3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35\n",
       "2    24\n",
       "3    21\n",
       "5    17\n",
       "7    17\n",
       "6    13\n",
       "4    10\n",
       "0     8\n",
       "Name: GRADE, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In preparation for turning this into a \"good grade/bad grade scenario\" (C's get degrees?)\n",
    "# Check to see that there are both \"good\" (4, 5, 6, 7) and \"bad\" (0, 1, 2, 3) grades\n",
    "encoded_student_df['GRADE'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1ccad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>3_1</th>\n",
       "      <th>3_2</th>\n",
       "      <th>3_3</th>\n",
       "      <th>9_1</th>\n",
       "      <th>9_2</th>\n",
       "      <th>9_3</th>\n",
       "      <th>9_4</th>\n",
       "      <th>10_1</th>\n",
       "      <th>10_2</th>\n",
       "      <th>10_3</th>\n",
       "      <th>10_4</th>\n",
       "      <th>14_1</th>\n",
       "      <th>14_2</th>\n",
       "      <th>14_3</th>\n",
       "      <th>15_1</th>\n",
       "      <th>15_2</th>\n",
       "      <th>15_3</th>\n",
       "      <th>15_4</th>\n",
       "      <th>15_5</th>\n",
       "      <th>16_1</th>\n",
       "      <th>16_2</th>\n",
       "      <th>16_3</th>\n",
       "      <th>16_4</th>\n",
       "      <th>16_5</th>\n",
       "      <th>23_1</th>\n",
       "      <th>23_2</th>\n",
       "      <th>23_3</th>\n",
       "      <th>24_1</th>\n",
       "      <th>24_2</th>\n",
       "      <th>24_3</th>\n",
       "      <th>28_1</th>\n",
       "      <th>28_2</th>\n",
       "      <th>28_3</th>\n",
       "      <th>COURSE ID_1</th>\n",
       "      <th>COURSE ID_2</th>\n",
       "      <th>COURSE ID_3</th>\n",
       "      <th>COURSE ID_4</th>\n",
       "      <th>COURSE ID_5</th>\n",
       "      <th>COURSE ID_6</th>\n",
       "      <th>COURSE ID_7</th>\n",
       "      <th>COURSE ID_8</th>\n",
       "      <th>COURSE ID_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  4  5  6  7  8  11  12  13  17  18  19  20  21  22  25  26  27  29  \\\n",
       "0    2  0  3  1  0  0  1   1   2   3   3   2   2   1   1   1   3   2   1   1   \n",
       "1    2  0  3  1  0  0  1   2   3   2   2   2   2   1   1   1   3   2   3   2   \n",
       "2    2  0  3  0  0  0  2   2   2   2   2   1   2   1   1   1   2   2   1   2   \n",
       "3    1  1  3  1  0  1  2   1   2   5   3   1   2   1   1   1   3   2   2   3   \n",
       "4    2  0  3  0  0  1  3   3   3   2   2   1   1   1   1   1   2   2   2   2   \n",
       "..  .. .. .. .. .. .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "140  2  1  3  1  1  0  1   1   2   2   3   3   2   1   1   1   2   1   2   3   \n",
       "141  1  1  4  0  0  0  1   1   1   5   3   2   2   0   1   2   3   2   2   5   \n",
       "142  1  1  4  0  0  0  1   3   4   4   2   2   2   1   1   1   3   3   2   4   \n",
       "143  2  1  4  1  1  1  5   4   4   1   2   2   1   1   1   1   2   1   2   5   \n",
       "144  1  1  5  0  0  0  3   3   1   5   3   1   1   1   1   1   3   2   3   5   \n",
       "\n",
       "     30  GRADE  3_1  3_2  3_3  9_1  9_2  9_3  9_4  10_1  10_2  10_3  10_4  \\\n",
       "0     1      0    0    0    1    1    0    0    0     1     0     0     0   \n",
       "1     3      0    0    0    1    1    0    0    0     1     0     0     0   \n",
       "2     2      0    0    1    0    0    0    0    1     0     1     0     0   \n",
       "3     2      0    1    0    0    1    0    0    0     0     1     0     0   \n",
       "4     2      0    1    0    0    1    0    0    0     0     0     0     1   \n",
       "..   ..    ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
       "140   3      1    0    1    0    1    0    0    0     0     1     0     0   \n",
       "141   3      1    0    1    0    0    0    0    1     0     1     0     0   \n",
       "142   3      0    1    0    0    1    0    0    0     1     0     0     0   \n",
       "143   3      1    0    1    0    0    1    0    0     0     0     1     0   \n",
       "144   4      0    1    0    0    1    0    0    0     1     0     0     0   \n",
       "\n",
       "     14_1  14_2  14_3  15_1  15_2  15_3  15_4  15_5  16_1  16_2  16_3  16_4  \\\n",
       "0       1     0     0     0     1     0     0     0     0     0     0     0   \n",
       "1       1     0     0     0     1     0     0     0     1     0     0     0   \n",
       "2       1     0     0     0     1     0     0     0     1     0     0     0   \n",
       "3       1     0     0     0     1     0     0     0     1     0     0     0   \n",
       "4       1     0     0     0     1     0     0     0     0     0     0     1   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "140     0     1     0     0     1     0     0     0     0     0     0     1   \n",
       "141     1     0     0     0     1     0     0     0     1     0     0     0   \n",
       "142     1     0     0     0     1     0     0     0     0     0     0     1   \n",
       "143     1     0     0     0     0     1     0     0     0     0     1     0   \n",
       "144     1     0     0     0     1     0     0     0     0     0     0     1   \n",
       "\n",
       "     16_5  23_1  23_2  23_3  24_1  24_2  24_3  28_1  28_2  28_3  COURSE ID_1  \\\n",
       "0       1     1     0     0     1     0     0     0     1     0            1   \n",
       "1       0     1     0     0     1     0     0     0     1     0            1   \n",
       "2       0     1     0     0     1     0     0     1     0     0            1   \n",
       "3       0     1     0     0     0     1     0     1     0     0            1   \n",
       "4       0     0     1     0     1     0     0     1     0     0            1   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...          ...   \n",
       "140     0     1     0     0     1     0     0     1     0     0            0   \n",
       "141     0     1     0     0     1     0     0     1     0     0            0   \n",
       "142     0     1     0     0     1     0     0     1     0     0            0   \n",
       "143     0     0     1     0     1     0     0     1     0     0            0   \n",
       "144     0     0     1     0     1     0     0     1     0     0            0   \n",
       "\n",
       "     COURSE ID_2  COURSE ID_3  COURSE ID_4  COURSE ID_5  COURSE ID_6  \\\n",
       "0              0            0            0            0            0   \n",
       "1              0            0            0            0            0   \n",
       "2              0            0            0            0            0   \n",
       "3              0            0            0            0            0   \n",
       "4              0            0            0            0            0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "140            0            0            0            0            0   \n",
       "141            0            0            0            0            0   \n",
       "142            0            0            0            0            0   \n",
       "143            0            0            0            0            0   \n",
       "144            0            0            0            0            0   \n",
       "\n",
       "     COURSE ID_7  COURSE ID_8  COURSE ID_9  \n",
       "0              0            0            0  \n",
       "1              0            0            0  \n",
       "2              0            0            0  \n",
       "3              0            0            0  \n",
       "4              0            0            0  \n",
       "..           ...          ...          ...  \n",
       "140            0            0            1  \n",
       "141            0            0            1  \n",
       "142            0            0            1  \n",
       "143            0            0            1  \n",
       "144            0            0            1  \n",
       "\n",
       "[145 rows x 64 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make this a binary problem, replace \"bad\" grades with \"0\", and \"good\"\n",
    "# grades with \"1\"\n",
    "binary_student_df = encoded_student_df\n",
    "binary_student_df['GRADE'] = binary_student_df['GRADE'].replace({1:0, 2:0, 3:0, 4:1, 5:1, 6:1, 7:1})\n",
    "binary_student_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b66edb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 63)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate Features X from Target y\n",
    "y = binary_student_df['GRADE']\n",
    "X = binary_student_df.drop(columns='GRADE')\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "790ee31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9444444444444444\n",
      "Testing Data Score: 0.8108108108108109\n",
      "Accuracy Score: 0.8108108108108109\n",
      "[[21  1]\n",
      " [ 6  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Bad Grade       0.78      0.95      0.86        22\n",
      "  Good Grade       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.84      0.78      0.79        37\n",
      "weighted avg       0.83      0.81      0.80        37\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "70            1       1\n",
       "128           0       0\n",
       "79            1       0\n",
       "11            0       0\n",
       "117           0       0\n",
       "105           1       1\n",
       "64            0       0\n",
       "13            0       0\n",
       "10            0       0\n",
       "125           0       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Logistic Regression Model and check accuracy\n",
    "classifier = LogisticRegression(solver='lbfgs', max_iter=200, random_state=10)\n",
    "classifier.fit(X_train, y_train)\n",
    "target_names = [\"Bad Grade\", \"Good Grade\"]\n",
    "predictions = classifier.predict(X_test)\n",
    "results_df = pd.DataFrame({'Prediction': predictions, 'Actual': y_test})\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, predictions)}\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, target_names=target_names))\n",
    "results_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13deb632",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "Let's see if we can do better. Accuracy score is 81%, but several \"Good\" grades are being predicted as \"Bad\". If a professor were using this algorithm to grant permission to attempt their course, some students would be needlessly rejected.<br><br>\n",
    "\"Fine-tuning parameters in Logistic Regression\" By Saturn Cloud, Monday, July 10, 2023, https://saturncloud.io/blog/finetuning-parameters-in-logistic-regression/ was consulted for ways to optimize this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b695456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to be used for optimization of the model\n",
    "def BinomialLogRegress(C, class_weight, solver, max_iter, X_train, X_test, y_train, y_test):\n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter=maxiters, random_state=10)\n",
    "\n",
    "    # Fit (train) model using the training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    # Determine performance \n",
    "    print(results)\n",
    "    target_names = [\"Bad Grade\", \"Good Grade\"]\n",
    "    print(f\"Number of iterations: {maxiters}\")\n",
    "    print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "    print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "    print(f\"Accuracy Score: {acc_score}\")\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c6f57d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction  Actual\n",
      "37            0       0\n",
      "0             0       0\n",
      "17            0       0\n",
      "15            0       0\n",
      "45            0       0\n",
      "40            0       0\n",
      "85            1       1\n",
      "89            1       1\n",
      "30            0       1\n",
      "27            0       0\n",
      "115           0       0\n",
      "93            0       1\n",
      "126           0       0\n",
      "60            0       0\n",
      "77            0       1\n",
      "121           0       0\n",
      "96            1       1\n",
      "101           0       1\n",
      "33            0       0\n",
      "74            1       1\n",
      "57            1       1\n",
      "32            0       0\n",
      "80            0       1\n",
      "6             0       1\n",
      "18            0       0\n",
      "107           1       1\n",
      "72            1       1\n",
      "70            1       1\n",
      "128           0       0\n",
      "79            1       0\n",
      "11            0       0\n",
      "117           0       0\n",
      "105           1       1\n",
      "64            0       0\n",
      "13            0       0\n",
      "10            0       0\n",
      "125           0       0\n",
      "Number of iterations: 100\n",
      "Training Data Score: 0.9444444444444444\n",
      "Testing Data Score: 0.8108108108108109\n",
      "Accuracy Score: 0.8108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Bad Grade       0.78      0.95      0.86        22\n",
      "  Good Grade       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.84      0.78      0.79        37\n",
      "weighted avg       0.83      0.81      0.80        37\n",
      "\n",
      "     Prediction  Actual\n",
      "37            0       0\n",
      "0             0       0\n",
      "17            0       0\n",
      "15            0       0\n",
      "45            0       0\n",
      "40            0       0\n",
      "85            1       1\n",
      "89            1       1\n",
      "30            0       1\n",
      "27            0       0\n",
      "115           0       0\n",
      "93            0       1\n",
      "126           0       0\n",
      "60            0       0\n",
      "77            0       1\n",
      "121           0       0\n",
      "96            1       1\n",
      "101           0       1\n",
      "33            0       0\n",
      "74            1       1\n",
      "57            1       1\n",
      "32            0       0\n",
      "80            0       1\n",
      "6             0       1\n",
      "18            0       0\n",
      "107           1       1\n",
      "72            1       1\n",
      "70            1       1\n",
      "128           0       0\n",
      "79            1       0\n",
      "11            0       0\n",
      "117           0       0\n",
      "105           1       1\n",
      "64            0       0\n",
      "13            0       0\n",
      "10            0       0\n",
      "125           0       0\n",
      "Number of iterations: 150\n",
      "Training Data Score: 0.9444444444444444\n",
      "Testing Data Score: 0.8108108108108109\n",
      "Accuracy Score: 0.8108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Bad Grade       0.78      0.95      0.86        22\n",
      "  Good Grade       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.84      0.78      0.79        37\n",
      "weighted avg       0.83      0.81      0.80        37\n",
      "\n",
      "     Prediction  Actual\n",
      "37            0       0\n",
      "0             0       0\n",
      "17            0       0\n",
      "15            0       0\n",
      "45            0       0\n",
      "40            0       0\n",
      "85            1       1\n",
      "89            1       1\n",
      "30            0       1\n",
      "27            0       0\n",
      "115           0       0\n",
      "93            0       1\n",
      "126           0       0\n",
      "60            0       0\n",
      "77            0       1\n",
      "121           0       0\n",
      "96            1       1\n",
      "101           0       1\n",
      "33            0       0\n",
      "74            1       1\n",
      "57            1       1\n",
      "32            0       0\n",
      "80            0       1\n",
      "6             0       1\n",
      "18            0       0\n",
      "107           1       1\n",
      "72            1       1\n",
      "70            1       1\n",
      "128           0       0\n",
      "79            1       0\n",
      "11            0       0\n",
      "117           0       0\n",
      "105           1       1\n",
      "64            0       0\n",
      "13            0       0\n",
      "10            0       0\n",
      "125           0       0\n",
      "Number of iterations: 200\n",
      "Training Data Score: 0.9444444444444444\n",
      "Testing Data Score: 0.8108108108108109\n",
      "Accuracy Score: 0.8108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Bad Grade       0.78      0.95      0.86        22\n",
      "  Good Grade       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.84      0.78      0.79        37\n",
      "weighted avg       0.83      0.81      0.80        37\n",
      "\n",
      "     Prediction  Actual\n",
      "37            0       0\n",
      "0             0       0\n",
      "17            0       0\n",
      "15            0       0\n",
      "45            0       0\n",
      "40            0       0\n",
      "85            1       1\n",
      "89            1       1\n",
      "30            0       1\n",
      "27            0       0\n",
      "115           0       0\n",
      "93            0       1\n",
      "126           0       0\n",
      "60            0       0\n",
      "77            0       1\n",
      "121           0       0\n",
      "96            1       1\n",
      "101           0       1\n",
      "33            0       0\n",
      "74            1       1\n",
      "57            1       1\n",
      "32            0       0\n",
      "80            0       1\n",
      "6             0       1\n",
      "18            0       0\n",
      "107           1       1\n",
      "72            1       1\n",
      "70            1       1\n",
      "128           0       0\n",
      "79            1       0\n",
      "11            0       0\n",
      "117           0       0\n",
      "105           1       1\n",
      "64            0       0\n",
      "13            0       0\n",
      "10            0       0\n",
      "125           0       0\n",
      "Number of iterations: 300\n",
      "Training Data Score: 0.9444444444444444\n",
      "Testing Data Score: 0.8108108108108109\n",
      "Accuracy Score: 0.8108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Bad Grade       0.78      0.95      0.86        22\n",
      "  Good Grade       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.84      0.78      0.79        37\n",
      "weighted avg       0.83      0.81      0.80        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See if precision for \"Bad Grade\" and recall for \"Good Grade\" improves with more iterations & where it stops improving\n",
    "summary_column_labels = ['C', 'Class Weight', 'Solver', 'Max Iterations', 'Accuracy']\n",
    "C_vals = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "class_weights = ['None', 'balanced']\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "max_iters = [100, 150, 200, 300]\n",
    "for C in C_vals:\n",
    "    for weight in class_weights:\n",
    "        for solver in solvers:\n",
    "            for iter in max_iters:\n",
    "                BinomialLogRegress(C, weight, solver, iter, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd7d62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02fb3cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([  0,   1,   3,   4,   7,   8,   9,  10,  11,  12,\\n            ...\\n            131, 132, 133, 135, 137, 138, 139, 140, 141, 143],\\n           dtype='int64', length=116)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m rskf\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[1;32m----> 7\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, X[test_index]\n\u001b[0;32m      8\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n\u001b[0;32m     10\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([  0,   1,   3,   4,   7,   8,   9,  10,  11,  12,\\n            ...\\n            131, 132, 133, 135, 137, 138, 139, 140, 141, 143],\\n           dtype='int64', length=116)] are in the [columns]\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430928e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9062a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec80442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e5a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc8351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0904ae5b",
   "metadata": {},
   "source": [
    "# Try Multinomial Logistic Regression\n",
    "\n",
    "So, that's nice. All of the students who recieved \"bad\" grades were accurately flagged, along with some students who actually received good grades. So, services could be offered to the flagged students. It won't hurt those who don't need the services, but no one who needs them is omitted. Nice. <br><hr>\n",
    "<strong>But,</strong> the original dataset had the grades subdivided into more \"normal\" categories, roughly corresponding to letter grades. To classify this, we need a Multinomial Logistic Regression.<br>\n",
    "<br>\n",
    "\"Changing logistic regression from binomial to multinomial probability requires a change to the loss function used to train the model (e.g. log loss to cross-entropy loss), and a change to the output from a single probability value to one probability for each class label.\" by Jason Brownlee on January 1, 2021 in Python Machine Learning, https://machinelearningmastery.com/multinomial-logistic-regression-with-python/<br>\n",
    "<br>The Multinomial Logistic Regression Model used here is shown on the above referenced website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaee09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_student_df=student_df = pd.read_sql(sql_query, engine)\n",
    "multi_student_df=multi_student_df.drop(\"STUDENT ID\", axis=1)\n",
    "multi_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31314176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features X from Target y using the multi_student_df\n",
    "y = multi_student_df['GRADE']\n",
    "X = multi_student_df.drop(columns='GRADE')\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Logistic Regression Model\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=10)\n",
    "\n",
    "# Fit (train) model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b42f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine performance\n",
    "target_names = [\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaf225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to use to test different max_iterations\n",
    "def LogRegress(maxiters, X_train, X_test, y_train, y_test):\n",
    "    classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=maxiters, random_state=10)\n",
    "\n",
    "    # Fit (train) model using the training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
    "    \n",
    "    # Determine performance \n",
    "    target_names = [\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "    print(f\"Number of iterations: {maxiters}\")\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if accuracy improves with more iterations & where it stops improving\n",
    "test_iters = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "for iter in test_iters:\n",
    "    LogRegress(iter, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0caeb3f",
   "metadata": {},
   "source": [
    "##### Even with 1000 iterations, the max Accuracy achieved was 24% and that was with 300 iterations. After this point, Accuracy decreased with more iterations.\n",
    "Next try tuning the penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of models using max_iters=300 and various values of \"C\" which\n",
    "# is the penalty weight\n",
    "def make_models():\n",
    "    multi_log_reg_models = dict()\n",
    "    for penalty in [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "        # create model name\n",
    "        key = '%.4f' % penalty\n",
    "        # set penalty to \"none\" when penalty = 0.0\n",
    "        if penalty==0.0:\n",
    "            multi_log_reg_models[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=300, random_state=10, penalty='none')\n",
    "        else:\n",
    "            multi_log_reg_models[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=300, random_state=10, penalty='l2', C=penalty)\n",
    "    return multi_log_reg_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6965c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = make_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    score = evaluate_model(model, X_train,X_test, y_train, y_test)\n",
    "    results.append(score)  # store the accuracy for the model\n",
    "    names.append(name)      # store the model name\n",
    "    print(f\"{name} has an accuracy of {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551b215",
   "metadata": {},
   "source": [
    "The warning says to scale the data, so let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fit the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Logistic Regression Model\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=300, random_state=10, penalty='l2', C=1.0)\n",
    "\n",
    "# Fit (train) model using the training data\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe9126",
   "metadata": {},
   "source": [
    "The accuracy score for the Multinomial Logistic Regression for this dataset is an abysmal 24% most likely because the dataset does not have enough observations for the number of features. There is a standard in ML of min observations = 10 * features, so this dataset needs to be double the size. Perhaps we can remove some of the features. Also, there may be features producing \"noise\". Next step, have a look at how each of the features correlates to the target \"GRADE\". An explanation of how to do this is here: https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e. <br>\n",
    "To visualize feature correlation to the target, produce correlation matrix with heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cedfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873d9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the data\n",
    "X = multi_student_df.iloc[:,0:31]  #independent columns\n",
    "y = multi_student_df.iloc[:,31]    #target column i.e GRADE\n",
    "\n",
    "#get correlations of each feature in the dataset\n",
    "correlation_matrix = multi_student_df.corr()\n",
    "top_corr_features = correlation_matrix.index\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot heat map\n",
    "g=sns.heatmap(multi_student_df[top_corr_features].corr(), annot=True, cmap=\"Pastel1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation values to determine which features to use in the model\n",
    "correlations = correlation_matrix.iloc[-1,:]\n",
    "\n",
    "# take the absolute values of the correlations and sort them in descending order\n",
    "abs_corr = correlations.abs()\n",
    "sorted_abs_corr = abs_corr.sort_values(ascending=False)\n",
    "print(f\"Absolute values of correlations with GRADE: {sorted_abs_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names for the features with 10 highest absolute values of correlations to use for the model\n",
    "top_corr_features = sorted_abs_corr.index[0:15]\n",
    "print(top_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_multi_student_df = multi_student_df[top_corr_features]\n",
    "reduced_multi_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5da84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features X from Target y using the reduced_multi_student_df\n",
    "y = reduced_multi_student_df['GRADE']\n",
    "X = reduced_multi_student_df.drop(columns='GRADE')\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95559efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Logistic Regression Model\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=400, random_state=10, penalty='l2', C=1.0)\n",
    "\n",
    "# Fit (train) model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842453e8",
   "metadata": {},
   "source": [
    "Accuracy is now 27%, and the best that I can understand from https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression , the solver and penalty are optimized as well as the number of max_iters. Next try the top 10 correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca33ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_corr_features = sorted_abs_corr.index[0:11]\n",
    "print(top_10_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_multi_student_df = multi_student_df[top_10_corr_features]\n",
    "ten_multi_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad73ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features X from Target y using the reduced_multi_student_df\n",
    "y = ten_multi_student_df['GRADE']\n",
    "X = ten_multi_student_df.drop(columns='GRADE')\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5be8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Logistic Regression Model\n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=400, random_state=10, penalty='l2', C=1.0)\n",
    "\n",
    "# Fit (train) model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a464ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e9d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9f4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3fafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c912c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fccbfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d304b33",
   "metadata": {},
   "source": [
    "# Try Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is already split into taining and testing datasets\n",
    "# Create decision tree classifier instance\n",
    "decision_tree_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fitting the model\n",
    "decision_tree_model = decision_tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ed2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, decision_tree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3072b38",
   "metadata": {},
   "source": [
    "# Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886af859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit Random Forest classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=3, random_state=10)\n",
    "random_forest_model = random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "random_forest_predictions = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Display Classification Report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, random_forest_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5b18f",
   "metadata": {},
   "source": [
    "# Try Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Sequential model\n",
    "keras_nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add an input Layer\n",
    "keras_nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=107))\n",
    "\n",
    "# Add the output layer\n",
    "keras_nn_model.add(tf.keras.layers.Dense(units=1, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "keras_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc18260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model and customize metrics\n",
    "keras_nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "fit_keras_nn_model = keras_nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = keras_nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bc879",
   "metadata": {},
   "source": [
    "The accuracy is very low. Suspect there may not be enough data points for the number of features. Also, there may be features producing \"noise\". Next step, have a look at how each of the features correlates to the target \"GRADE\". An explanation of how to do this is here: https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e.<br>\n",
    "To visualize feature correlation to the target, produce correlation matrix with heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data\n",
    "X = student_df.iloc[:,0:31]  #independent columns\n",
    "y = student_df.iloc[:,31]    #target column i.e GRADE\n",
    "\n",
    "#get correlations of each feature in the dataset\n",
    "correlation_matrix = student_df.corr()\n",
    "top_corr_features = correlation_matrix.index\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot heat map\n",
    "g=sns.heatmap(student_df[top_corr_features].corr(), annot=True, cmap=\"RdYlGn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation values to determine which features to use in the model\n",
    "correlations = correlation_matrix.iloc[-1,:]\n",
    "\n",
    "# take the absolute values of the correlations and sort them in descending order\n",
    "abs_corr = correlations.abs()\n",
    "sorted_abs_corr = abs_corr.sort_values(ascending=False)\n",
    "print(f\"Absolute values of correlations with GRADE: {sorted_abs_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09038c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names for the features with 10 highest absolute values of correlations to use for the model\n",
    "top_corr_features = sorted_abs_corr.index[0:15]\n",
    "print(top_corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad686226",
   "metadata": {},
   "source": [
    "# 2nd Logistic Regression Model\n",
    "\n",
    "Following the rule of 10 and using features that are more highly correlated than the rest.<br>\n",
    "Also, after reading this article: https://medium.com/geekculture/machine-learning-one-hot-encoding-vs-integer-encoding-f180eb831cf1 , I will try not using OneHotEncoding as the data is already integer encoded. If the results are sub par, then use OneHotEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_student_df = student_df[top_corr_features]\n",
    "reduced_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ae72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upon refering to the documentation for the dataset:\n",
    "# binary features: 2, 20, 5 , reassign the value '2' to '0' for these features \n",
    "# Features to OneHotEncode because no ordinal relationship between the values: 21, 9, COURSE ID, 28, 3\n",
    "mapping_dict = {2:0, 1:1}  # Defines the mapping dictionary\n",
    "reduced_student_df.loc[:,['2', '20', '5']] = reduced_student_df[['2', '20', '5']].applymap(mapping_dict.get)\n",
    "reduced_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc2 = OneHotEncoder(sparse_output=False)\n",
    "categorical2 = ['21', '9', 'COURSE ID', '28', '3']\n",
    "\n",
    "# Fit and transfor OneHotEncoder\n",
    "encode_reduced_student_df = pd.DataFrame(enc2.fit_transform(reduced_student_df[categorical2]))\n",
    "\n",
    "# Add the encoded features to the dataframe\n",
    "encode_reduced_student_df.columns = enc2.get_feature_names_out(categorical2)\n",
    "encode_reduced_student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ab26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge OneHotEncoder features and drop the originals\n",
    "reduced_student_encode_df = reduced_student_df\n",
    "reduced_student_encode_df = reduced_student_encode_df.merge(encode_reduced_student_df, left_index=True, right_index=True)\n",
    "reduced_student_encode_df = reduced_student_encode_df.drop(columns=categorical2)\n",
    "reduced_student_encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split preprocessed reduced data into features and target arrays\n",
    "y = reduced_student_encode_df['GRADE'].values\n",
    "X = reduced_student_encode_df.drop(\"GRADE\", axis=1).values\n",
    "\n",
    "# Split data into testing and training datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12147400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data values are very similar, StandardScaler is not needed\n",
    "# Create a Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)\n",
    "\n",
    "# Fit (train) model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine performance\n",
    "target_names = [\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b33b6",
   "metadata": {},
   "source": [
    "The accuracy went from 38% to 24%. <br>\n",
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is already split into taining and testing datasets\n",
    "# Create decision tree classifier instance\n",
    "decision_tree_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fitting the model\n",
    "decision_tree_model = decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bf3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, decision_tree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5d79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
